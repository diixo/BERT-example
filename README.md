# BERT-example

Train text from: https://archive.org/stream/StructureAndInterpretationOfComputerProgramsSecondEdition/sicp_djvu.txt

* **demo-1.py** - simple demo with training on small text
* **demo-synthesis.py** - create `wordpiece-tokenizer-base.json` with synthetic tokens
* **demo-2.py** - `tokens.txt` as external
* **demo-3.py** - `tokens.txt` with tokenization training corpus
